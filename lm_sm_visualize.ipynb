{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LOAD PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import napari\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from napari_animation import Animation\n",
    "\n",
    "\n",
    "# import custum colormaps\n",
    "from colormaps import *\n",
    "\n",
    "# import custum functions\n",
    "from STP_plotting import *\n",
    "from STP_processing import *\n",
    "\n",
    "# auto refreshes imported functions if source code changes:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up vars\n",
    "home_dir = \"/Volumes/Data/\"\n",
    "# home_dir = \"/mnt/labNAS/\"\n",
    "\n",
    "# in_path = home_dir+\"Emily/STP_for_MAPseq/4_python_output/input_tifs/\"\n",
    "out_path = home_dir+\"Emily/STP_for_MAPseq/4_python_output/output_figs/\"\n",
    "\n",
    "metadata = pd.read_csv(\"stp_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reference brain\n",
    "\n",
    "# # 220429\n",
    "# ref_path = home_dir+\"Emily/STP_for_MAPseq/2_fiji_adjusted/OMC_STeg_220429_b2_hand_straightened_asr.tif\"\n",
    "# ref_brain = \"OMC_STeg_220429_b2\"\n",
    "\n",
    "# 220411\n",
    "ref_path = home_dir+\"Emily/STP_for_MAPseq/2_fiji_adjusted/OMC_STeg_220411_b3_hand_straightened_asr.tif\"\n",
    "ref_in = home_dir+\"Emily/STP_for_MAPseq/3_brainreg_output/OMC_STeg_220411_straight_aligned_asr_aligned_10um/\"\n",
    "ref_brain = \"OMC_STeg_220411_b1\"\n",
    "\n",
    "# # # 220208\n",
    "# # ref_path = home_dir+\"Emily/STP_for_MAPseq/2_fiji_adjusted/OMC_STeg_220208_b1_hand_straightened_asl.tif\"\n",
    "# ref_brain = \"OMC_STeg_220208_b0\"\n",
    "ref_in = home_dir+\"Emily/STP_for_MAPseq/3_brainreg_output/OMC_STeg_220208_straight_aligned_asr_aligned_10um/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on ref brain, get path to brains\n",
    "omc_meta = metadata[metadata[\"inj_site\"]==\"OMC\"].reset_index(drop=True)\n",
    "\n",
    "# get in_path based on reference brain\n",
    "ref_name = ref_brain[4:-3]\n",
    "in_path = home_dir+\"Emily/STP_for_MAPseq/3_brainreg_output/\"+ref_name+\"_aligned/\"\n",
    "\n",
    "tif_paths = []\n",
    "for brain in omc_meta[\"brain\"]:\n",
    "    if brain==ref_brain:\n",
    "        tif_paths.append(ref_path)\n",
    "    else:\n",
    "        path = in_path+brain+\"_brainreg_\"+ref_name+\"/downsampled_standard.tiff\"\n",
    "        tif_paths.append(path)\n",
    "\n",
    "omc_meta[\"paths\"] = tif_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.2 ms, sys: 1.31 s, total: 1.37 s\n",
      "Wall time: 35.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# import images\n",
    "start = time\n",
    "tifs = []\n",
    "for path in omc_meta[\"paths\"]:\n",
    "    tif = tf.imread(path)\n",
    "    tifs.append(tif)\n",
    "len(tifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create images for mmus and steg\n",
    "mmus_avg = np.mean(np.array(tifs[:3]), axis=0)\n",
    "steg_avg = np.mean(np.array(tifs[3:]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import example singing mouse\n",
    "# # import hand-straight brain\n",
    "# steg_to_st_tif = in_path+\"norm_subtracted/STeg_220429_aligned/OMC_STeg_220208_b0_aligned_to_STeg_220429_NO_subtracted.tif\"\n",
    "\n",
    "# # import 230429 STeg brain- seems to be brighter than others???\n",
    "# steg_hs_asr = home_dir+\"Emily/STP_for_MAPseq/2_fiji_adjusted/OMC_STeg_220429_b2_hand_straightened_asr.tif\"\n",
    "\n",
    "# # # import example lab mouse\n",
    "# # mmus_tif = home_dir+\"Emily/STP_for_MAPseq/2_fiji_adjusted/OMC_MMus_220303_b1_hand_straightened_asr.tif\"\n",
    "\n",
    "\n",
    "# # import example lab mouse aligned to sm\n",
    "# mmus_to_st_tif = in_path+\"norm_subtracted/STeg_220429_aligned/OMC_MMus_220119_b0_aligned_to_STeg_220429_NO_subtracted.tif\"\n",
    "\n",
    "\n",
    "# # load tifs\n",
    "# steg_to_st = tf.imread(steg_to_st_tif)\n",
    "# # mmus = tf.imread(mmus_tif)\n",
    "# steg = tf.imread(steg_hs_asr)\n",
    "# mmus_to_st_b0 = tf.imread(mmus_to_st_tif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boundaries\n",
    "# import aligned to hand-straight\n",
    "boundaries_path = ref_in+\"boundaries_downsize.tif\"\n",
    "boundaries = tf.imread(boundaries_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brain</th>\n",
       "      <th>species</th>\n",
       "      <th>inj_site</th>\n",
       "      <th>shape</th>\n",
       "      <th>paths</th>\n",
       "      <th>name</th>\n",
       "      <th>contrast_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OMC_MMus_220119_b0</td>\n",
       "      <td>MMus</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...</td>\n",
       "      <td>MMus_220119</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMC_MMus_220303_b1</td>\n",
       "      <td>MMus</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...</td>\n",
       "      <td>MMus_220303</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMC_MMus_220324_b2</td>\n",
       "      <td>MMus</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...</td>\n",
       "      <td>MMus_220324</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMC_STeg_220208_b0</td>\n",
       "      <td>STeg</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...</td>\n",
       "      <td>STeg_220208</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OMC_STeg_220411_b1</td>\n",
       "      <td>STeg</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/2_fiji_adju...</td>\n",
       "      <td>STeg_220411</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OMC_STeg_220429_b2</td>\n",
       "      <td>STeg</td>\n",
       "      <td>OMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...</td>\n",
       "      <td>STeg_220429</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                brain species inj_site  shape  \\\n",
       "0  OMC_MMus_220119_b0    MMus      OMC    NaN   \n",
       "1  OMC_MMus_220303_b1    MMus      OMC    NaN   \n",
       "2  OMC_MMus_220324_b2    MMus      OMC    NaN   \n",
       "3  OMC_STeg_220208_b0    STeg      OMC    NaN   \n",
       "4  OMC_STeg_220411_b1    STeg      OMC    NaN   \n",
       "5  OMC_STeg_220429_b2    STeg      OMC    NaN   \n",
       "\n",
       "                                               paths         name  \\\n",
       "0  /Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...  MMus_220119   \n",
       "1  /Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...  MMus_220303   \n",
       "2  /Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...  MMus_220324   \n",
       "3  /Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...  STeg_220208   \n",
       "4  /Volumes/Data/Emily/STP_for_MAPseq/2_fiji_adju...  STeg_220411   \n",
       "5  /Volumes/Data/Emily/STP_for_MAPseq/3_brainreg_...  STeg_220429   \n",
       "\n",
       "   contrast_factor  \n",
       "0              7.0  \n",
       "1              5.0  \n",
       "2              3.0  \n",
       "3              2.0  \n",
       "4              3.5  \n",
       "5              7.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omc_meta[\"name\"] = [brain[4:-3] for brain in omc_meta[\"brain\"]]\n",
    "omc_meta[\"contrast_factor\"]= [7, 5, 3, 2, 3.5, 7]\n",
    "omc_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "# # add steg avg\n",
    "# viewer.add_image(\n",
    "#     steg_avg,\n",
    "#     scale=[50,20,20]\n",
    "# )\n",
    "\n",
    "# # add mmus avg\n",
    "# viewer.add_image(\n",
    "#     mmus_avg,\n",
    "#     scale=[50,20,20]\n",
    "# )\n",
    "\n",
    "# add individual tifs\n",
    "\n",
    "# just load STeg_220411 and MMus_220303\n",
    "# select_is = [1,4]\n",
    "\n",
    "for i in range(len(tifs)):\n",
    "    viewer.add_image(\n",
    "        tifs[i],\n",
    "        name=omc_meta.loc[i,\"brain\"],\n",
    "        scale=[50,20,20]\n",
    "    )\n",
    "    # set contrast\n",
    "    # adjust contrast limits, set max to max/contrast_factor\n",
    "    cf = omc_meta.loc[i,\"contrast_factor\"]\n",
    "    max_contrast = viewer.layers[omc_meta.loc[i,\"brain\"]].contrast_limits[1]\n",
    "    viewer.layers[omc_meta.loc[i,\"brain\"]].contrast_limits = [0, max_contrast/cf]\n",
    "\n",
    "    # custom contrast for 220411 and 220303\n",
    "    # if i == 1:\n",
    "    #     cf = 1301\n",
    "    # elif i ==4:\n",
    "    #     cf = 1423\n",
    "    viewer.layers[omc_meta.loc[i,\"brain\"]].contrast_limits = [0, cf]\n",
    "\n",
    "\n",
    "# add scale bar\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add example image\n",
    "# viewer.add_image(\n",
    "#     boundaries,\n",
    "#     scale=[50,20,20],\n",
    "#     blending=\"additive\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save screen shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# manipulate in napari until get orientation you want...\n",
    "# take screenshot, specify size for highres\n",
    "file_name = \"mm2200324_alignto_st220411_z206_BS.png\"\n",
    "size = tifs[0].shape[1:]\n",
    "viewer.screenshot(out_path+file_name, canvas_only=True, size=size)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given slice number save pic from each animal\n",
    "z = 113\n",
    "label=\"_AudR\"\n",
    "\n",
    "for i in range(omc_meta.shape[0]):\n",
    "    brain_name = omc_meta.loc[i,\"name\"]\n",
    "    \n",
    "    # open viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # load image\n",
    "    viewer.add_image(\n",
    "        tifs[i],\n",
    "        name=brain_name,\n",
    "        scale=[50,20,20],\n",
    "    )\n",
    "    \n",
    "    # adjust contrast limits, set max to max/contrast_factor\n",
    "    cf = omc_meta.loc[i,\"contrast_factor\"]\n",
    "\n",
    "    max_contrast = viewer.layers[brain_name].contrast_limits[1]\n",
    "    viewer.layers[brain_name].contrast_limits = [0, max_contrast/cf]\n",
    "\n",
    "    # add scale bar\n",
    "    viewer.scale_bar.visible = True\n",
    "    viewer.scale_bar.unit = \"um\"\n",
    "\n",
    "    # take screenshot\n",
    "    file_name = brain_name+\"_align_st220411_z\"+str(z)+label+\".png\"\n",
    "    size = tifs[i].shape[1:]\n",
    "    viewer.screenshot(out_path+file_name, canvas_only=True, size=size)\n",
    "\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/374 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1646, 970) to (1648, 976) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 374/374 [00:19<00:00, 18.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# try saving animation\n",
    "\n",
    "animation = Animation(viewer)\n",
    "viewer.update_console({\"animation\": animation})\n",
    "\n",
    "# scroll through, pause on z45, 57, 100, 128, 167\n",
    "\n",
    "viewer.dims.current_step = (0, 0, 0)\n",
    "animation.capture_keyframe()\n",
    "\n",
    "# # OMCi/OMCc - SM\n",
    "# viewer.dims.current_step = (45, 0, 0)\n",
    "# animation.capture_keyframe(steps=45)\n",
    "# # pause here for 0.5 secs\n",
    "# animation.capture_keyframe()\n",
    "# animation.capture_keyframe(steps=5)\n",
    "\n",
    "# # OMCi/OMCc - LM\n",
    "# viewer.dims.current_step = (57, 0, 0)\n",
    "# animation.capture_keyframe(steps=12)\n",
    "# # pause here for 0.5 secs\n",
    "# animation.capture_keyframe()\n",
    "# animation.capture_keyframe(steps=5)\n",
    "\n",
    "# decided to change to one OMCi/c site\n",
    "viewer.dims.current_step = (50, 0, 0)\n",
    "animation.capture_keyframe(steps=50)\n",
    "# pause here for 0.5 secs\n",
    "animation.capture_keyframe()\n",
    "animation.capture_keyframe(steps=5)\n",
    "\n",
    "# STR\n",
    "viewer.dims.current_step = (100, 0, 0)\n",
    "animation.capture_keyframe(steps=43)\n",
    "# pause here for 0.5 secs\n",
    "animation.capture_keyframe()\n",
    "animation.capture_keyframe(steps=5)\n",
    "\n",
    "# AudR, TH, SNr\n",
    "viewer.dims.current_step = (128, 0, 0)\n",
    "animation.capture_keyframe(steps=28)\n",
    "# pause here for 1.5 secs\n",
    "animation.capture_keyframe()\n",
    "animation.capture_keyframe(steps=15)\n",
    "\n",
    "\n",
    "# PAG, SCm, PG\n",
    "viewer.dims.current_step = (167, 0, 0)\n",
    "animation.capture_keyframe(steps=39)\n",
    "# pause here for 1.5 secs\n",
    "animation.capture_keyframe()\n",
    "animation.capture_keyframe(steps=15)\n",
    "\n",
    "# go through to end\n",
    "viewer.dims.current_step = (280, 0, 0)\n",
    "animation.capture_keyframe(steps=113)\n",
    "\n",
    "animation.animate(out_path+\"steg_220411_pauses.mp4\", quality=9, fps=10, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:13<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:11<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:10<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:11<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:11<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/211 [00:00<?, ?it/s]IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1192, 858) to (1200, 864) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "100%|██████████| 211/211 [00:10<00:00, 19.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# create loop to create animation for each individual animal\n",
    "\n",
    "for i in range(omc_meta.shape[0]):\n",
    "    brain_name = omc_meta.loc[i,\"name\"]\n",
    "    \n",
    "    # open viewer\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    # load image\n",
    "    viewer.add_image(\n",
    "        tifs[i],\n",
    "        name=brain_name,\n",
    "        scale=[50,20,20],\n",
    "    )\n",
    "    \n",
    "    # adjust contrast limits, set max to max/contrast_factor\n",
    "    cf = omc_meta.loc[i,\"contrast_factor\"]\n",
    "\n",
    "    max_contrast = viewer.layers[brain_name].contrast_limits[1]\n",
    "    viewer.layers[brain_name].contrast_limits = [0, max_contrast/cf]\n",
    "\n",
    "    # add scale bar\n",
    "    viewer.scale_bar.visible = True\n",
    "    viewer.scale_bar.unit = \"um\"\n",
    "\n",
    "    # create animation\n",
    "    animation = Animation(viewer)\n",
    "    viewer.update_console({\"animation\": animation})\n",
    "\n",
    "    viewer.dims.current_step = (0, 0, 0)\n",
    "    animation.capture_keyframe()\n",
    "    viewer.dims.current_step = (70, 0, 0)\n",
    "    animation.capture_keyframe(steps=70)\n",
    "    viewer.dims.current_step = (140, 0, 0)\n",
    "    animation.capture_keyframe(steps=70)\n",
    "    viewer.dims.current_step = (280, 0, 0)\n",
    "    animation.capture_keyframe(steps=70)\n",
    "    animation.animate(out_path+brain_name+\"_aligned_steg_220411.mp4\", quality=9, fps=10, canvas_only=True)\n",
    "\n",
    "    viewer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
